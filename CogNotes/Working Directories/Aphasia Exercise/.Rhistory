articulation_rate_nsyll_phonationtime = as.numeric(articulation_rate_nsyll_phonationtime),
asd_speakingtime_nsyll = as.numeric(asd_speakingtime_nsyll),
condition = as.factor(condition)
)
# Arranging plots in a grid using the package gridExtra
pacman::p_load(gridExtra)
grid.arrange(
analysis("Speech rate", aphasia$speechrate_nsyll_dur),
analysis("N pauses", aphasia$npause),
analysis("N syllables", aphasia$nsyll),
analysis("Phonation time", aphasia$phonationtime_s),
analysis("Articulation rate", aphasia$articulation_rate_nsyll_phonationtime),
analysis("Speaking time", aphasia$asd_speakingtime_nsyll),
analysis("Pause rate", aphasia$pauserate)
)
# Training data (Aphasia and Control)
trainingset <- aphasia %>%
filter(condition != "Secret")
# Test data (Secret)
testset <- aphasia %>%
filter(condition == "Secret")
# Training data (Aphasia and Control)
trainingset <- aphasia %>%
filter(condition != "Secret")
# Test data (Secret)
testset <- aphasia %>%
filter(condition == "Secret")
# Check the format of your data
str(trainingset)
# Now we can see that our condition is a 2-level factor with "0" or "1"
str(trainingset$condition)
# Releveling the condition factor to use "0" (Control) as the reference (see how it's used with ?relevel)
trainingset <- trainingset %>%
mutate(
condition = relevel(condition, "0")
)
# Check the format of your data
str(trainingset)
# Changing the labels of your training data: Make Control into "0" and Aphasia into "1"
trainingset <- trainingset %>%
mutate(condition = as.factor(if_else(condition == "Control", 0, 1)))
# Now we can see that our condition is a 2-level factor with "0" or "1"
str(trainingset$condit
ion)
# Now we can see that our condition is a 2-level factor with "0" or "1"
str(trainingset$condition)
# Releveling the condition factor to use "0" (Control) as the reference (see how it's used with ?relevel)
trainingset <- trainingset %>%
mutate(
condition = relevel(condition, ref="0")
)
# Creating the glm model:
model <- glm(condition ~ articulation_rate_nsyll_phonationtime, data = trainingset, family = binomial())
# Looking at the results:
summary(model)
# Creating the glm model:
model <- glm(condition ~ pauserate, data = trainingset, family = binomial())
# Looking at the results:
summary(model)
# Creating the glm model:
model <- glm(condition ~ asd_speakingtime_nsyll, data = trainingset, family = binomial())
# Creating the glm model:
model <- glm(condition ~ asd_speakingtime_nsyll, data = trainingset, family = binomial())
# Looking at the results:
summary(model)
# Creating the glm model:
model <- glm(condition ~ speechrate_nsyll_dur, data = trainingset, family = binomial())
# Creating the glm model:
model <- glm(condition ~ speechrate_nsyll_dur, data = trainingset, family = binomial())
# Looking at the results:
summary(model)
# Creating the glm model:
model <- glm(condition ~ asd_speakingtime_nsyll, data = trainingset, family = binomial())
# Creating the glm model:
model <- glm(condition ~ asd_speakingtime_nsyll, data = trainingset, family = binomial())
# Looking at the results:
summary(model)
# Adding the predicted probabilities:
trainingset <- trainingset %>%
mutate(predictions_perc = inv.logit(predict(model)))
# Using the BIC() function, evaluate the models side-by-side
# The smaller the value, the better the model
BIC(model)
# Adding the predicted probabilities:
trainingset <- trainingset %>%
mutate(predictions_perc = inv.logit(predict(model)))
# Adding the predicted probabilities:
trainingset <- trainingset %>%
mutate(predictions_perc = inv.logit(predict(model)))
# Adding the predicted probabilities:
trainingset <- trainingset %>%
mutate(predictions_perc = inv.logit(predict(model)))
# Assigning predicted conditions based on their probabilities (remember to make it a factor)
trainingset <- trainingset %>%
mutate(prediction = as.factor(if_else(predictions_perc<0.5, 0, 1)))
# Making a confusion matrix:
conf_matrix <- confusionMatrix(trainingset$prediction, reference = trainingset$condition, positive= "1")
# Making a confusion matrix:
conf_matrix <- confusionMatrix(trainingset$prediction, reference = trainingset$condition, positive= "1")
conf_matrix$table %>%
as_tibble() %>%
ggplot() +
aes(Prediction, Reference, fill=n, label=n) +
geom_tile() +
geom_text(color="white") +
coord_cartesian(expand=FALSE) +
theme_minimal() +
theme(legend.position = "none")
# ROC curve
rocCurve <- roc(response = trainingset$condition, trainingset$predictions_perc)
# Area under that curve
auc(rocCurve)
# Confidence interval
ci(rocCurve)
# Plotting the ROC curve over the chance (diagonal line) level
plot(rocCurve, legacy.axes = TRUE)
# Predictions on the test dataset:
testset <- testset %>%
mutate(
model_predictions_perc = inv.logit(predict(model, testset, na.action = na.omit, allow.new.levels = T ))
)
# Based on the probability, convert to 0s and 1s
testset <- testset %>%
mutate(
model_predictions = as.factor(if_else(model_predictions_perc < 0.5, 0, 1))
)
pacman::p_load(tidyverse, readbulk, lme4, ggplot2)
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
View(df)
df1 <- df %>%
filter(condition = 1)
df1 <- df %>%
filter(condition = 1)
df1 <- df %>%
filter(condition == 1)
View(df1)
df3 <- df %>%
filter(condition == 3)
df2 <- df %>%
filter(condition == 2)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k))
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
df <- df %>%
filter(word %in% rownames(EN_100k))
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k))
df1 = control
df1 <- df %>%
filter(condition == 1)
df2 = garden
df2 <- df %>%
filter(condition == 2)
df3 <- df %>%
filter(condition == 3)
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k))
#df1 = control
df1 <- df %>%
filter(condition == 1)
#df2 = garden
df2 <- df %>%
filter(condition == 2)
#df3 = crops
df3 <- df %>%
filter(condition == 3)
knitr::opts_chunk$set(echo = TRUE)
# import/load packages
# LSAfun is used for the semantic analysis. We will load a pretrained semantic model to get semantic distances between each animal name. See more documentation here: https://cran.r-project.org/web/packages/LSAfun/LSAfun.pdf
# ggrepel is a package that allow us to show text in ggplot without it overlapping with the data points (it provides an improved alternative to geom_text())
# ape is a package that we can use to make fancy dendogram network plots
pacman::p_load(tidyverse, LSAfun, ggrepel, ape, plyr, dplyr, ggplot2)
rowwise()?
rowwise()?
rowwise()?
rowwise?
View(df1)
View(df3)
df1 %>% group_by()
test <- df1 %>%
group_by(id)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
mutate(word2 = lag(word)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE)) %>%
drop_na()
View(test)
View(test)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, garden, method="euclidean",tvectors=EN_100k)) %>%
filter(word %in% rownames(EN_100k)) %>%
mutate(word2 = lag(word)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE)) %>%
drop_na()
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
filter(word %in% rownames(EN_100k)) %>%
mutate(word2 = lag(word)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE)) %>%
drop_na()
View(test)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
filter(word %in% rownames(EN_100k)) %>%
mutate(word2 = lag(word)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE)) %>%
drop_na()
View(test)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k))
View(test)
aggregate()?
filter(word %in% rownames(EN_100k)) %>%
mutate(word2 = lag(word)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE)) %>%
drop_na()
?aggregate()
aggregate(test, id, mean)
aggregate(test, list(test$id), mean)
aggregate(test$sem_dist, list(test$id), mean)
test2 <- aggregate(test$sem_dist, list(test$id), mean)
View(test2)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
aggregate(sem_dist, list(id), mean)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
aggregate(sem_dist, list(df1$id), mean)
View(test)
df1mutated <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
aggregate(df1mutated$sem_dist, list(df1mutated$id), mean)
df1mutated <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
aggregate(df1mutated$sem_dist, list(df1mutated$id), mean)
df1mutated <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
df1done <- aggregate(df1mutated$sem_dist, list(df1mutated$id), mean)
df1mutated <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
df1done <- aggregate(df1mutated$sem_dist, list(df1mutated$id), mean)
#df2 = garden
df2 <- df %>%
filter(condition == 2)
test <- df2 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k))
df2_2 <- aggregate(test$sem_dist, list(test$id), mean)
View(test2)
View(df2_2)
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k)) %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k))
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k)) %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k))
df <- df %>%
filter(word %in% rownames(EN_100k)) %>%
dplyr::mutate(sem_dist = distance(word, word2, method="euclidean",tvectors=EN_100k))
df <- df %>%
filter(word %in% rownames(EN_100k))
#df1 = control
df1 <- df %>%
filter(condition == 1)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k))
df1_1 <- aggregate(test$sem_dist, list(test$id), mean)
#df2 = garden
df2 <- df %>%
filter(condition == 2)
test <- df2 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k))
df2_2 <- aggregate(test$sem_dist, list(test$id), mean)
#df3 = crops
df3 <- df %>%
filter(condition == 3)
test <- df3 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k))
df3_3 <- aggregate(test$sem_dist, list(test$id), mean)
View(df3_3)
View(df1_1)
View(df2_2)
mean(df1_1$x)
mean(df2_2$x)
mean(df3_3$x)
mutate(sem_dist=scale(sem_dist, center = F))
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist=scale(sem_dist, center = F))
df <- readbulk::read_bulk("logfiles",extension=".csv",verbose=F)
load("EN_100k.rda")
df <- df %>%
filter(word %in% rownames(EN_100k))
#df1 = control
df1 <- df %>%
filter(condition == 1)
test <- df1 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist=scale(sem_dist, center = F))
df1_1 <- aggregate(test$sem_dist, list(test$id), mean)
#df2 = garden
df2 <- df %>%
filter(condition == 2)
test <- df2 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist=scale(sem_dist, center = F))
df2_2 <- aggregate(test$sem_dist, list(test$id), mean)
#df3 = crops
df3 <- df %>%
filter(condition == 3)
test <- df3 %>%
group_by(id) %>%
filter(word %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word, "garden", method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist=scale(sem_dist, center = F))
df3_3 <- aggregate(test$sem_dist, list(test$id), mean)
mean(df1_1$x)
mean(df2_2$x)
mean(df3_3$x)
View(df3_3)
mean(df1_1$x)
View(df2_2)
mean(df1_1$V1)
mean(df2_2$V1)
mean(df3_3$V1)
df2_2 <- aggregate(Sem_dist = test$sem_dist, list(test$id), mean)
df2_2 <- aggregate(Sem_dist = test$sem_dist, list(test$id), mean)
df2_2 <- aggregate(test$sem_dist, list(test$id), mean)
df2_2 <- aggregate(test$sem_dist, list(test$id), mean)
df2_2 <- aggregate(test$sem_dist, list(id=test$id), mean)
View(df2_2)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, LSAfun, ggrepel, ape, plyr, dplyr, ggplot2, car)
df <- read_csv("clean_dist.csv")
load("EN_100k.rda")
df <- df %>%
filter(word1 %in% rownames(EN_100k)) %>%
filter(word2 %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word1, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE))
df <- df %>%
filter(word1 %in% rownames(EN_100k)) %>%
filter(word2 %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word1, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE))
df <- aggregate(df$sem_dist, list(df$id, df$condition), mean)
View(df)
test %>%
ggplot(aes(sample = V1)) + stat_qq() +
stat_qq_line()
df <- aggregate(df$sem_dist, list(df$id, df$condition), mean)
df <- aggregate(df$sem_dist, list(df$id, df$condition), mean)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, LSAfun, ggrepel, ape, plyr, dplyr, ggplot2, car)
df <- read_csv("clean_dist.csv")
load("EN_100k.rda")
df <- df %>%
filter(word1 %in% rownames(EN_100k)) %>%
filter(word2 %in% rownames(EN_100k)) %>%
rowwise() %>%
dplyr::mutate(sem_dist = distance(word1, word2, method="euclidean",tvectors=EN_100k)) %>%
mutate(sem_dist = scale(sem_dist, center = FALSE))
View(df)
df <- aggregate(df$sem_dist, list(df$id, df$condition), mean)
#Condition 1
test1 <- test %>%
filter(Group.2 == 1)
View(df)
ggplot(df3, aes(V1))+
geom_histogram(aes(y = ..density..), binwidth = .02)+
stat_function(fun = dnorm, args = list(mean = mean(df3$V1), sd = sd(df3$V1)), color = "red", size = 1)+
theme_bw()
#Condition 1
df1 <- df %>%
filter(Group.2 == 1)
ggplot(df1, aes(V1))+
geom_histogram(aes(y = ..density..), binwidth = .02)+
stat_function(fun = dnorm, args = list(mean = mean(df1$V1), sd = sd(df1$V1)), color = "red", size = 1)+
theme_bw()
#Condition 2
df2 <- df %>%
filter(Group.2 == 2)
ggplot(df2, aes(V1))+
geom_histogram(aes(y = ..density..), binwidth = .02)+
stat_function(fun = dnorm, args = list(mean = mean(df2$V1), sd = sd(df2$V1)), color = "red", size = 1)+
theme_bw()
#Condition 3
df3 <- df %>%
filter(Group.2 == 3)
ggplot(df3, aes(V1))+
geom_histogram(aes(y = ..density..), binwidth = .02)+
stat_function(fun = dnorm, args = list(mean = mean(df3$V1), sd = sd(df3$V1)), color = "red", size = 1)+
theme_bw()
round(pastecs::stat.desc(cbind(sem_dist3 = df3$V1, sem_dist2=df2$V1, sem_dist1 = df1$V1), basic = FALSE, norm = TRUE, desc = FALSE), digits = 2)
df <- mutate(
Group.2 = as.factor(Group.2)
,df)
str(test$Group.2)
df <- mutate(
Group.2 = as.factor(Group.2)
,df)
str(df$Group.2)
summary(aov(df$V1 ~ df$Group.2))
summary(lm(df$V1 ~ df$Group.2))
pairwise.t.test(df$V1, df$Group.2, p.adjust.method = "bonferroni")
model1 <- lm(word_embedding~condition)
model1 <- lm(word_embedding~condition)
model1 <- lm(word_embedding~condition, data=df)
View(df)
model1<-lm(V1~Group.2,data = df)
plot(model1)
car::durbinWatsonTest(model1)
car::durbinWatsonTest(model1)
plot(model1)
vif(model1)
vif(model1)
plot(model1,1)
plot(model1,4)
plot(model1,1)
plot(model1,2)
model1<-lm(V1~Group.2,data = df)
plot(model1,1)
plot(model1,2)
plot(model1,3)
plot(model1,4)
car::durbinWatsonTest(model1)
plot(model1,3)
plot(model1,4)
plot(model1,3)
plot(model1,2)
plot(model1,1)
View(model1)
model1<-lm(V1~Group.2,data = df)
plot(model1,1)
plot(model1,2)
plot(model1,3)
plot(model1,4)
car::durbinWatsonTest(model1)
car::durbinWatsonTest(model1)
